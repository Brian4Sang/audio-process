#!/usr/bin/env python3
"""
äººå£°åˆ†ç¦»åŸºäº Demucs

åŠŸèƒ½ï¼šå°†åŒ…å«èƒŒæ™¯éŸ³ä¹æˆ–æ··åˆä¿¡å·çš„éŸ³é¢‘è¿›è¡Œåˆ†ç¦»ï¼Œåªä¿ç•™æŒ‡å®šéŸ³è½¨ï¼ˆå¦‚ vocalsï¼‰ã€‚

å¯é…ç½®å‚æ•°ï¼š
- input_dir          è¾“å…¥éŸ³é¢‘ç›®å½•ï¼ˆ.wavï¼‰
- output_dir         è¾“å‡ºåˆ†ç¦»åéŸ³é¢‘ç›®å½•
- --track            è¦ä¿ç•™çš„éŸ³è½¨åï¼ˆé»˜è®¤ä¸º vocalsï¼‰
- --model            ä½¿ç”¨çš„åˆ†ç¦»æ¨¡å‹ï¼ˆå¦‚ htdemucsï¼‰
- --overwrite        æ˜¯å¦è¦†ç›–å·²æœ‰è¾“å‡ºæ–‡ä»¶
- --logdir           ä¿å­˜å¤„ç†æ—¥å¿—çš„ç›®å½•ï¼ˆä½¿ç”¨ StageLoggerï¼‰
- --recursive        æ˜¯å¦é€’å½’æŸ¥æ‰¾å­ç›®å½•ï¼ˆé»˜è®¤å¼€å¯ï¼‰
- --num_workers_per_gpu å¹¶å‘è¿›ç¨‹æ•°ï¼ˆå¤š GPUï¼‰
- --strict-check     æ˜¯å¦è·³è¿‡ä¸ç¬¦åˆDemucsè¦æ±‚çš„éŸ³é¢‘
"""

#!/usr/bin/env python3
import multiprocessing as mp
from pathlib import Path
from typing import TYPE_CHECKING
import json

import click
from loguru import logger
from tqdm import tqdm
import soundfile as sf

from fish_audio_preprocess.utils.file import AUDIO_EXTENSIONS, list_files, make_dirs
from fish_audio_preprocess.utils.stage_logger import StageLogger

if TYPE_CHECKING:
    import torch


def worker(
    input_dir: str,
    output_dir: str,
    recursive: bool,
    overwrite: bool,
    track: list[str],
    model: str,
    shifts: int,
    device: "torch.device",
    shard_idx: int = -1,
    total_shards: int = 1,
    logdir: str = None,
    strict_check: bool = True,
):
    from fish_audio_preprocess.utils.separate_audio import (
        init_model,
        load_track,
        merge_tracks,
        save_audio,
        separate_audio,
    )

    logger_obj = StageLogger(f"separate_shard{shard_idx}", logdir) if logdir else None
    files = list_files(input_dir, extensions=AUDIO_EXTENSIONS, recursive=recursive)
    if shard_idx >= 0:
        files = [f for i, f in enumerate(files) if i % total_shards == shard_idx]

    shard_name = f"[Shard {shard_idx + 1}/{total_shards}]"
    logger.info(f"{shard_name} Found {len(files)} files, separating audio")

    _model = init_model(model, device)

    for file in tqdm(
        files,
        desc=f"{shard_name} Separating audio",
        position=0 if shard_idx < 0 else shard_idx,
        leave=False,
    ):
        if logger_obj:
            logger_obj.log_total()

        relative_path = file.relative_to(input_dir)
        new_file = output_dir / relative_path

        if new_file.exists() and not overwrite:
            if logger_obj:
                logger_obj.log_skipped(str(file), reason="å·²å­˜åœ¨,æœªè®¾ç½® overwrite")
            continue

        try:
            info = sf.info(str(file))
            if strict_check:
                if info.samplerate not in [44100, 48000] or info.channels != 2:
                    reason = f"å½“å‰éŸ³é¢‘: {info.samplerate}Hz, {info.channels}ch,ä¸æ»¡è¶³ Demucs è¦æ±‚"
                    logger.warning(f"âš ï¸ è·³è¿‡: {file} - {reason}")
                    if logger_obj:
                        logger_obj.log_skipped(str(file), reason=reason)
                    continue
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•è¯»å–éŸ³é¢‘ä¿¡æ¯ {file}: {e}")
            if logger_obj:
                logger_obj.log_failed(str(file), reason=f"éŸ³é¢‘ä¿¡æ¯è¯»å–å¤±è´¥: {e}")
            continue

        try:
            source = load_track(_model, file)
            separated = separate_audio(_model, source, shifts=shifts, num_workers=0)
            merged = merge_tracks(separated, track)
            save_audio(_model, new_file, merged)
            if logger_obj:
                logger_obj.log_success()
        except Exception as e:
            logger.warning(f"âŒ Failed to separate {file}: {e}")
            if logger_obj:
                logger_obj.log_failed(str(file), reason=str(e))

    if logger_obj:
        logger_obj.save()

    logger.info(f"{shard_name} Finished.")


@click.command()
@click.argument("input_dir", type=click.Path(exists=True, file_okay=False))
@click.argument("output_dir", type=click.Path(exists=False, file_okay=False))
@click.option("--recursive/--no-recursive", default=True, help="Search recursively")
@click.option("--overwrite/--no-overwrite", default=False, help="Overwrite existing files")
@click.option("--clean/--no-clean", default=False, help="Clean output directory before processing")
@click.option("--track", "-t", multiple=True, help="Name of track(s) to keep", default=["vocals"])
@click.option("--model", help="Name of model to use", default="htdemucs")
@click.option("--shifts", help="Number of shifts, improves separation quality a bit", default=1)
@click.option("--num_workers_per_gpu", help="Number of workers per GPU", default=2)
@click.option("--logdir", type=click.Path(file_okay=False), default=None, help="Directory to save processing logs")
@click.option(
    "--strict-check/--no-strict-check",
    default=True,
    show_default=True,
    help="æ˜¯å¦è·³è¿‡é‡‡æ ·ç‡æˆ–é€šé“æ•°ä¸æ»¡è¶³ Demucs è¦æ±‚çš„éŸ³é¢‘ï¼ˆ44100/48000Hzä¸”ä¸ºåŒå£°é“ï¼‰"
)
def separate(
    input_dir: str,
    output_dir: str,
    recursive: bool,
    overwrite: bool,
    clean: bool,
    track: list[str],
    model: str,
    shifts: int,
    num_workers_per_gpu: int,
    logdir: str,
    strict_check: bool,
):
    """
    Separates audio in input_dir using model and saves to output_dir.
    """

    input_dir, output_dir = Path(input_dir), Path(output_dir)
    if input_dir == output_dir and clean:
        logger.error("You are trying to clean the input directory, aborting")
        return

    make_dirs(output_dir, clean)

    base_args = (
        input_dir,
        output_dir,
        recursive,
        overwrite,
        track,
        model,
        shifts,
    )

    import torch

    if torch.cuda.is_available() and torch.cuda.device_count() >= 1:
        logger.info(f"Using {torch.cuda.device_count()} GPU(s)...")
        mp.set_start_method("spawn", force=True)
        processes = []
        shards = torch.cuda.device_count() * num_workers_per_gpu
        for shard_idx in range(shards):
            p = mp.Process(
                target=worker,
                args=(
                    *base_args,
                    torch.device(f"cuda:{shard_idx % torch.cuda.device_count()}"),
                    shard_idx,
                    shards,
                    logdir,
                    strict_check,
                ),
            )
            p.start()
            processes.append(p)
        for p in processes:
            p.join()
    else:
        logger.info("âš ï¸ CUDA not available. Falling back to CPU...")
        worker(
            *base_args,
            torch.device("cpu"),
            shard_idx=-1,
            total_shards=1,
            logdir=logdir,
            strict_check=strict_check,
        )

    # âœ… åˆå¹¶æ—¥å¿—
    if logdir:
        merged_file, summary = merge_stage_logs(logdir)
        logger.info(f"âœ… åˆå¹¶æ—¥å¿—å®Œæˆï¼š{logdir}/{merged_file}")
        logger.info(f"ğŸ“Š æ—¥å¿—æ±‡æ€»: {summary}")


# âœ… é™„åŠ æ—¥å¿—åˆå¹¶å·¥å…·
def merge_stage_logs(logdir: str, prefix: str = "separate_shard", merged_name: str = "separate_log.json"):
    logdir = Path(logdir)
    merged = {
        "stage": "separate",
        "summary": {"total": 0, "success": 0, "skipped": 0, "failed": 0},
        "skipped": [],
        "failed": []
    }

    shard_logs = list(logdir.glob(f"{prefix}*_log.json"))

    for log_file in logdir.glob(f"{prefix}*_log.json"):
        with open(log_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            merged["summary"]["total"] += data["summary"].get("total", 0)
            merged["summary"]["success"] += data["summary"].get("success", 0)
            merged["summary"]["skipped"] += data["summary"].get("skipped", 0)
            merged["summary"]["failed"] += data["summary"].get("failed", 0)
            merged["skipped"].extend(data.get("skipped", []))
            merged["failed"].extend(data.get("failed", []))

    merged_path = logdir / merged_name
    with open(merged_path, "w", encoding="utf-8") as f:
        json.dump(merged, f, indent=2, ensure_ascii=False)

    # âœ… åˆ é™¤å•ç‹¬çš„ shard æ—¥å¿—
    for log_file in shard_logs:
        log_file.unlink()

    return merged_path.name, merged["summary"]


if __name__ == "__main__":
    separate()
